{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Constants\n",
    "beta_0 = 2.0\n",
    "beta_1 = 3.0\n",
    "n_samples = 100\n",
    "sigma = 1.0  # Standard deviation of the noise\n",
    "\n",
    "# Generate synthetic data\n",
    "X = 10 * np.random.rand(n_samples)\n",
    "epsilon = np.random.normal(0, sigma, n_samples)\n",
    "Y = beta_0 + beta_1 * X + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, invgamma\n",
    "\n",
    "# Prior distributions\n",
    "def prior_beta_0():\n",
    "    return norm(0, 10).rvs()\n",
    "\n",
    "def prior_beta_1():\n",
    "    return norm(0, 10).rvs()\n",
    "\n",
    "def prior_sigma2():\n",
    "    return invgamma(1).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(X, Y, beta_0, beta_1, sigma2):\n",
    "    Y_pred = beta_0 + beta_1 * X\n",
    "    residuals = Y - Y_pred\n",
    "    return np.prod(norm(loc=0, scale=np.sqrt(sigma2)).pdf(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_posterior(X, Y, num_samples=10000):\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        b0 = prior_beta_0()\n",
    "        b1 = prior_beta_1()\n",
    "        s2 = prior_sigma2()\n",
    "        post = likelihood(X, Y, b0, b1, s2) * norm(0, 10).pdf(b0) * norm(0, 10).pdf(b1) * invgamma(1).pdf(s2)\n",
    "        samples.append((b0, b1, s2, post))\n",
    "    \n",
    "    # Normalize the posterior probability (for simplicity, consider it unnormalized here)\n",
    "    return samples\n",
    "\n",
    "# Generate samples from the posterior\n",
    "posterior_samples = monte_carlo_posterior(X, Y, num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated beta_0: 2.166892014785945\n",
      "Estimated beta_1: 2.9566554039577913\n",
      "Estimated sigma^2: 0.8220087340441655\n"
     ]
    }
   ],
   "source": [
    "# Extracting samples and weights\n",
    "beta_0_samples = [s[0] for s in posterior_samples]\n",
    "beta_1_samples = [s[1] for s in posterior_samples]\n",
    "sigma2_samples = [s[2] for s in posterior_samples]\n",
    "weights = [s[3] for s in posterior_samples]\n",
    "\n",
    "# Compute weighted averages\n",
    "beta_0_est = np.average(beta_0_samples, weights=weights)\n",
    "beta_1_est = np.average(beta_1_samples, weights=weights)\n",
    "sigma2_est = np.average(sigma2_samples, weights=weights)\n",
    "\n",
    "print(f\"Estimated beta_0: {beta_0_est}\")\n",
    "print(f\"Estimated beta_1: {beta_1_est}\")\n",
    "print(f\"Estimated sigma^2: {sigma2_est}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
